{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "X5x4LRR4mmNl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import string\n",
        "import requests\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pWbkV7dS1t11"
      },
      "outputs": [],
      "source": [
        "response = requests.get('https://github.com/Manikandan029/TNSDC-Generative-AI/blob/main/adele.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LhORy3loaRc"
      },
      "outputs": [],
      "source": [
        "data=response.text.splitlines()\n",
        "print(data[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFHkpYMvod6E",
        "outputId": "8874f865-1cf2-48d6-eb06-23e1f629c382"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2400"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_3CiKOD188B"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNMkkZYQohJ0",
        "outputId": "8bd54190-98f0-438e-9815-870f1f634182"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "91330"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(\" \".join(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eZnbItGiojej"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "L7Bi7RVWom7t"
      },
      "outputs": [],
      "source": [
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKLzVn43orcQ",
        "outputId": "9ac83c37-6cdf-434c-bfdc-978ef1562da3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[254, 21, 219, 725],\n",
              " [117, 8, 80, 153, 3, 133],\n",
              " [14, 10, 726, 727],\n",
              " [41, 56, 2, 603, 3, 728, 1, 68, 517, 2, 40, 3, 518, 41],\n",
              " [1, 23, 107, 189, 300, 9, 57],\n",
              " [286, 35, 46, 10, 230],\n",
              " [2, 83, 134, 4, 519, 8, 120],\n",
              " [1, 37, 520, 102, 19, 27, 25, 254, 21, 328, 11],\n",
              " [27, 209, 11, 13, 9, 124],\n",
              " [42, 67, 210, 125]]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_text=tokenizer.texts_to_sequences(data)\n",
        "encoded_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7-0j-pKyowPP"
      },
      "outputs": [],
      "source": [
        "wc=tokenizer.word_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "A9bN7X_XoyB2"
      },
      "outputs": [],
      "source": [
        "wi=tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBVMvFNaoywE",
        "outputId": "4ec0f465-5848-412a-b93c-d2104e6d5565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique words and total vocab size: 1396\n"
          ]
        }
      ],
      "source": [
        "print(f\"Number of unique words and total vocab size: {len(tokenizer.word_counts)+1}\")\n",
        "vocab_size=len(tokenizer.word_counts)+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vl2tcvHBo1D2"
      },
      "outputs": [],
      "source": [
        "x=[\"play this song\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhlqWxX9o4cr",
        "outputId": "fd7b02bc-73a2-40ed-8316-6cc14bb042cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[241, 44, 409]]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.texts_to_sequences(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHTOYv7Lo6yn",
        "outputId": "a4ac7b8b-272b-4fe8-b98e-41f681906a66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[254, 21, 219, 725],\n",
              " [117, 8, 80, 153, 3, 133],\n",
              " [14, 10, 726, 727],\n",
              " [41, 56, 2, 603, 3, 728, 1, 68, 517, 2, 40, 3, 518, 41],\n",
              " [1, 23, 107, 189, 300, 9, 57],\n",
              " [286, 35, 46, 10, 230],\n",
              " [2, 83, 134, 4, 519, 8, 120],\n",
              " [1, 37, 520, 102, 19, 27, 25, 254, 21, 328, 11],\n",
              " [27, 209, 11, 13, 9, 124],\n",
              " [42, 67, 210, 125]]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " encoded_text[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8YYTHKQMo7vg"
      },
      "outputs": [],
      "source": [
        "data_list=[]\n",
        "for i in encoded_text:\n",
        "    if len(i)>1:\n",
        "        for j in range(2,len(i)):\n",
        "            data_list.append(i[:j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VIKxNcGRo_Av"
      },
      "outputs": [],
      "source": [
        "max_length=20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpLPTASLpAv8",
        "outputId": "1bc625c7-4be9-43b6-f5c8-9042b86ffcbb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 254,  21],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 254,  21, 219],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 117,   8],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 117,   8,  80],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 117,   8,  80, 153]], dtype=int32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences=pad_sequences(data_list,maxlen=max_length,padding=\"pre\") # we set the lenght size equal to 20\n",
        "sequences[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_bHy4qLpE4r",
        "outputId": "be21123d-53ef-4bc3-8f14-ee421932706e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(14231, 20)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sequences.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moBxLRwtpIOH",
        "outputId": "3890d69d-10fd-44ef-b6b5-0cd71068ba93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X values\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  254]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 254\n",
            "   21]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "  117]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 117\n",
            "    8]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 117   8\n",
            "   80]]\n",
            "------------------------------\n",
            "X values\n",
            "[ 21 219   8  80 153]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X=sequences[:,:-1]\n",
        "y=sequences[:,-1]\n",
        "print(\"X values\")\n",
        "print(X[:5]) # 5 sample\n",
        "print(\"-\"*30)\n",
        "print(\"X values\")\n",
        "print(y[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YbCesp_pKmH",
        "outputId": "8fbc5e47-1453-46f8-c2a7-b4a5a031be7c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14231, 19), (14231,))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape,y.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdWE-BdBpMvv",
        "outputId": "b7b9ffca-f0af-4bb5-dbf3-e0d8a13ffd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "Shape of y (14231, 1396)\n"
          ]
        }
      ],
      "source": [
        "y=to_categorical(y,num_classes=vocab_size)\n",
        "#since unique word number is vocab_size, thus there is vocab_size classes\n",
        "print(y[:5]) # 5 sample\n",
        "print(\"Shape of y\",y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZLIFyLjnpPcQ",
        "outputId": "88e14531-3edd-477c-fcf3-e100ca3ec168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X (14231, 19)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Shape of X\",X.shape)\n",
        "seq_length=X.shape[1]\n",
        "seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dGdS6YW1pRsL"
      },
      "outputs": [],
      "source": [
        "\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocab_size,50,input_length=seq_length))\n",
        "#The first layer is the Embedded layer that uses 50-length vectors\n",
        "#return_sequences=True because we add another LSTM\n",
        "model.add(LSTM(100,return_sequences=True))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(100,activation=\"relu\"))\n",
        "model.add(Dense(vocab_size,activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUh8IuuQpT6h",
        "outputId": "92008769-4b80-47fc-ce30-98720650ae58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 19, 50)            69800     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 19, 100)           60400     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               10100     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1396)              140996    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 361696 (1.38 MB)\n",
            "Trainable params: 361696 (1.38 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hcjyKAujpWi7"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=\"categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_eoHVTYpZsm",
        "outputId": "6906343f-5134-48b1-dfb2-9a4141625f60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "445/445 [==============================] - 20s 34ms/step - loss: 5.6961 - accuracy: 0.0453\n",
            "Epoch 2/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 5.2601 - accuracy: 0.0500\n",
            "Epoch 3/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 5.0394 - accuracy: 0.0572\n",
            "Epoch 4/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 4.8662 - accuracy: 0.0689\n",
            "Epoch 5/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 4.7220 - accuracy: 0.0782\n",
            "Epoch 6/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 4.5984 - accuracy: 0.0895\n",
            "Epoch 7/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 4.4756 - accuracy: 0.1003\n",
            "Epoch 8/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 4.3411 - accuracy: 0.1187\n",
            "Epoch 9/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 4.1985 - accuracy: 0.1411\n",
            "Epoch 10/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 4.0484 - accuracy: 0.1630\n",
            "Epoch 11/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 3.9050 - accuracy: 0.1854\n",
            "Epoch 12/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 3.7670 - accuracy: 0.2024\n",
            "Epoch 13/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 3.6354 - accuracy: 0.2143\n",
            "Epoch 14/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 3.5058 - accuracy: 0.2368\n",
            "Epoch 15/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 3.3863 - accuracy: 0.2530\n",
            "Epoch 16/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 3.2832 - accuracy: 0.2699\n",
            "Epoch 17/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 3.1810 - accuracy: 0.2834\n",
            "Epoch 18/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 3.0798 - accuracy: 0.3018\n",
            "Epoch 19/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.9907 - accuracy: 0.3180\n",
            "Epoch 20/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.9058 - accuracy: 0.3313\n",
            "Epoch 21/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 2.8235 - accuracy: 0.3479\n",
            "Epoch 22/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.7464 - accuracy: 0.3601\n",
            "Epoch 23/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.6730 - accuracy: 0.3764\n",
            "Epoch 24/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.6010 - accuracy: 0.3876\n",
            "Epoch 25/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 2.5334 - accuracy: 0.4023\n",
            "Epoch 26/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.4653 - accuracy: 0.4161\n",
            "Epoch 27/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.4071 - accuracy: 0.4302\n",
            "Epoch 28/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 2.3444 - accuracy: 0.4411\n",
            "Epoch 29/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 2.2892 - accuracy: 0.4532\n",
            "Epoch 30/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 2.2337 - accuracy: 0.4617\n",
            "Epoch 31/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 2.1802 - accuracy: 0.4749\n",
            "Epoch 32/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 2.1322 - accuracy: 0.4858\n",
            "Epoch 33/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 2.0862 - accuracy: 0.4933\n",
            "Epoch 34/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 2.0389 - accuracy: 0.5054\n",
            "Epoch 35/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.9909 - accuracy: 0.5178\n",
            "Epoch 36/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.9509 - accuracy: 0.5265\n",
            "Epoch 37/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.9057 - accuracy: 0.5356\n",
            "Epoch 38/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.8685 - accuracy: 0.5440\n",
            "Epoch 39/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.8316 - accuracy: 0.5501\n",
            "Epoch 40/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.8014 - accuracy: 0.5535\n",
            "Epoch 41/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.7572 - accuracy: 0.5659\n",
            "Epoch 42/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 1.7268 - accuracy: 0.5724\n",
            "Epoch 43/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 1.6928 - accuracy: 0.5789\n",
            "Epoch 44/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.6590 - accuracy: 0.5860\n",
            "Epoch 45/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.6212 - accuracy: 0.5987\n",
            "Epoch 46/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.5928 - accuracy: 0.6019\n",
            "Epoch 47/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.5613 - accuracy: 0.6117\n",
            "Epoch 48/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.5299 - accuracy: 0.6186\n",
            "Epoch 49/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 1.5011 - accuracy: 0.6228\n",
            "Epoch 50/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.4755 - accuracy: 0.6294\n",
            "Epoch 51/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 1.4477 - accuracy: 0.6348\n",
            "Epoch 52/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.4232 - accuracy: 0.6367\n",
            "Epoch 53/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.3994 - accuracy: 0.6449\n",
            "Epoch 54/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.3672 - accuracy: 0.6534\n",
            "Epoch 55/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.3599 - accuracy: 0.6548\n",
            "Epoch 56/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.3375 - accuracy: 0.6558\n",
            "Epoch 57/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.3022 - accuracy: 0.6678\n",
            "Epoch 58/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.2722 - accuracy: 0.6748\n",
            "Epoch 59/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.2501 - accuracy: 0.6815\n",
            "Epoch 60/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 1.2338 - accuracy: 0.6799\n",
            "Epoch 61/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 1.2094 - accuracy: 0.6860\n",
            "Epoch 62/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.1893 - accuracy: 0.6940\n",
            "Epoch 63/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.1757 - accuracy: 0.6936\n",
            "Epoch 64/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.1589 - accuracy: 0.6998\n",
            "Epoch 65/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.1366 - accuracy: 0.7018\n",
            "Epoch 66/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.1216 - accuracy: 0.7071\n",
            "Epoch 67/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.1086 - accuracy: 0.7089\n",
            "Epoch 68/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 1.0923 - accuracy: 0.7133\n",
            "Epoch 69/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 1.0727 - accuracy: 0.7185\n",
            "Epoch 70/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.0619 - accuracy: 0.7203\n",
            "Epoch 71/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 1.0533 - accuracy: 0.7249\n",
            "Epoch 72/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 1.0313 - accuracy: 0.7250\n",
            "Epoch 73/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 1.0141 - accuracy: 0.7318\n",
            "Epoch 74/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.9960 - accuracy: 0.7340\n",
            "Epoch 75/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.9829 - accuracy: 0.7409\n",
            "Epoch 76/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.9665 - accuracy: 0.7425\n",
            "Epoch 77/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.9559 - accuracy: 0.7456\n",
            "Epoch 78/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.9454 - accuracy: 0.7503\n",
            "Epoch 79/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.9286 - accuracy: 0.7502\n",
            "Epoch 80/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.9164 - accuracy: 0.7527\n",
            "Epoch 81/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.9062 - accuracy: 0.7548\n",
            "Epoch 82/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.8949 - accuracy: 0.7595\n",
            "Epoch 83/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.8861 - accuracy: 0.7622\n",
            "Epoch 84/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8724 - accuracy: 0.7678\n",
            "Epoch 85/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.8586 - accuracy: 0.7708\n",
            "Epoch 86/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.8436 - accuracy: 0.7714\n",
            "Epoch 87/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.8369 - accuracy: 0.7748\n",
            "Epoch 88/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.8295 - accuracy: 0.7756\n",
            "Epoch 89/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.8146 - accuracy: 0.7810\n",
            "Epoch 90/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.8070 - accuracy: 0.7796\n",
            "Epoch 91/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.7957 - accuracy: 0.7845\n",
            "Epoch 92/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.7861 - accuracy: 0.7841\n",
            "Epoch 93/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.7738 - accuracy: 0.7903\n",
            "Epoch 94/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.7689 - accuracy: 0.7907\n",
            "Epoch 95/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.7682 - accuracy: 0.7923\n",
            "Epoch 96/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.7588 - accuracy: 0.7937\n",
            "Epoch 97/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.7436 - accuracy: 0.7978\n",
            "Epoch 98/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.7387 - accuracy: 0.7981\n",
            "Epoch 99/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.7308 - accuracy: 0.8017\n",
            "Epoch 100/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.7243 - accuracy: 0.7999\n",
            "Epoch 101/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.7167 - accuracy: 0.8011\n",
            "Epoch 102/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.7068 - accuracy: 0.8050\n",
            "Epoch 103/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.7002 - accuracy: 0.8042\n",
            "Epoch 104/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 0.7028 - accuracy: 0.8056\n",
            "Epoch 105/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6908 - accuracy: 0.8069\n",
            "Epoch 106/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6883 - accuracy: 0.8080\n",
            "Epoch 107/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6811 - accuracy: 0.8100\n",
            "Epoch 108/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6726 - accuracy: 0.8143\n",
            "Epoch 109/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.6653 - accuracy: 0.8154\n",
            "Epoch 110/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6586 - accuracy: 0.8141\n",
            "Epoch 111/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6619 - accuracy: 0.8151\n",
            "Epoch 112/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.6544 - accuracy: 0.8158\n",
            "Epoch 113/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6416 - accuracy: 0.8203\n",
            "Epoch 114/150\n",
            "445/445 [==============================] - 15s 34ms/step - loss: 0.6412 - accuracy: 0.8182\n",
            "Epoch 115/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6405 - accuracy: 0.8207\n",
            "Epoch 116/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6306 - accuracy: 0.8212\n",
            "Epoch 117/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6350 - accuracy: 0.8227\n",
            "Epoch 118/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6351 - accuracy: 0.8222\n",
            "Epoch 119/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.6329 - accuracy: 0.8216\n",
            "Epoch 120/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.6287 - accuracy: 0.8207\n",
            "Epoch 121/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.6199 - accuracy: 0.8218\n",
            "Epoch 122/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 0.6117 - accuracy: 0.8255\n",
            "Epoch 123/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6091 - accuracy: 0.8262\n",
            "Epoch 124/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.5996 - accuracy: 0.8267\n",
            "Epoch 125/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.6083 - accuracy: 0.8251\n",
            "Epoch 126/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6052 - accuracy: 0.8278\n",
            "Epoch 127/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.6034 - accuracy: 0.8259\n",
            "Epoch 128/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.5969 - accuracy: 0.8271\n",
            "Epoch 129/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.5913 - accuracy: 0.8273\n",
            "Epoch 130/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.5886 - accuracy: 0.8285\n",
            "Epoch 131/150\n",
            "445/445 [==============================] - 17s 39ms/step - loss: 0.5883 - accuracy: 0.8282\n",
            "Epoch 132/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.5885 - accuracy: 0.8299\n",
            "Epoch 133/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 0.5836 - accuracy: 0.8314\n",
            "Epoch 134/150\n",
            "445/445 [==============================] - 17s 39ms/step - loss: 0.5768 - accuracy: 0.8307\n",
            "Epoch 135/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.5858 - accuracy: 0.8285\n",
            "Epoch 136/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.5828 - accuracy: 0.8281\n",
            "Epoch 137/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.5697 - accuracy: 0.8333\n",
            "Epoch 138/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.5657 - accuracy: 0.8343\n",
            "Epoch 139/150\n",
            "445/445 [==============================] - 16s 36ms/step - loss: 0.5771 - accuracy: 0.8313\n",
            "Epoch 140/150\n",
            "445/445 [==============================] - 17s 39ms/step - loss: 0.5634 - accuracy: 0.8343\n",
            "Epoch 141/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 0.5679 - accuracy: 0.8325\n",
            "Epoch 142/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.5766 - accuracy: 0.8292\n",
            "Epoch 143/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.5637 - accuracy: 0.8347\n",
            "Epoch 144/150\n",
            "445/445 [==============================] - 15s 35ms/step - loss: 0.5551 - accuracy: 0.8354\n",
            "Epoch 145/150\n",
            "445/445 [==============================] - 16s 35ms/step - loss: 0.5648 - accuracy: 0.8330\n",
            "Epoch 146/150\n",
            "445/445 [==============================] - 18s 40ms/step - loss: 0.5575 - accuracy: 0.8349\n",
            "Epoch 147/150\n",
            "445/445 [==============================] - 17s 37ms/step - loss: 0.5575 - accuracy: 0.8348\n",
            "Epoch 148/150\n",
            "445/445 [==============================] - 17s 38ms/step - loss: 0.5568 - accuracy: 0.8369\n",
            "Epoch 149/150\n",
            "445/445 [==============================] - 17s 39ms/step - loss: 0.5550 - accuracy: 0.8357\n",
            "Epoch 150/150\n",
            "445/445 [==============================] - 16s 37ms/step - loss: 0.5559 - accuracy: 0.8341\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e48f85ef5b0>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X,y,batch_size=32,epochs=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "hFmJdzwayn_3"
      },
      "outputs": [],
      "source": [
        "text_lenght= 15 # 15 words per line\n",
        "\n",
        "def generate_text(input_text, no_lines):\n",
        "    general_text=[]\n",
        "    for i in range(no_lines):\n",
        "        text=[]\n",
        "        for _ in range(text_lenght):\n",
        "            encoded=tokenizer.texts_to_sequences([input_text])\n",
        "            encoded=pad_sequences(encoded,maxlen=seq_length,padding=\"pre\")\n",
        "            y_pred=np.argmax(model.predict(encoded),axis=-1) # it will generate a word index, loop up into dictionary containing word index\n",
        "\n",
        "            predicted_word=\"\"\n",
        "            for word,index in tokenizer.word_index.items():\n",
        "                if index==y_pred:\n",
        "                    predicted_word=word\n",
        "                    break\n",
        "\n",
        "            input_text=input_text +' '+ predicted_word\n",
        "            text.append(predicted_word)\n",
        "\n",
        "        input_text=text[-1]\n",
        "        text=\" \".join(text) # input text will be the last word of first created line\n",
        "        general_text.append(text)\n",
        "\n",
        "    return general_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkSa7qGDyutn",
        "outputId": "e519607c-3483-478f-a2cc-559a54542203"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 996ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[\"i'm it make your heart behind me i would know i was so reckless if\",\n",
              " \"you're ready are you ready treat her love and make me imagine you're here find\",\n",
              " \"the things i think just don't make my heart the note that i want you\",\n",
              " \"know when to make me imagine you're here find yourself a forty fool on me\",\n",
              " \"i'm it make your heart behind me i would know i was so reckless if\",\n",
              " \"you're ready are you ready treat her love and make me imagine you're here find\"]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text=\"me\"\n",
        "text_produced=generate_text(input_text,6)\n",
        "text_produced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n0A-DB4y1Qm",
        "outputId": "505697a0-3976-4dde-a62a-8ba979dbe6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['never felt close you i remember all of my memories in my heart i been',\n",
              " 'i i miss my whole life hiding my heart away away woke up feeling heavy',\n",
              " 'i can know by the way you treat your face under every kind of your',\n",
              " \"love drives me crazy it's hard to understand just a one for of this would\",\n",
              " \"i have a figure but it's like i'm why this hurts 'cause i m sober\",\n",
              " 'and fell in your mouth the one for you in leave this on words trying']"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input_text=\"i want to see you\"\n",
        "text_produced=generate_text(input_text,6)\n",
        "text_produced"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
